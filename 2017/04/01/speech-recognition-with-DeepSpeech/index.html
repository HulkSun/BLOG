<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://hulksun.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"livere_uid","storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="摘要  Deep Speech是一个端到端的语音识别系统,该系统使用深度学习的方法取代了传统的特征提取方法,直接从根据波形文件产生的频谱图中提取特征生成对应的文字信息。该系统使用门限循环单元构建的循环神经网络能够对具有时间序列相关性的语音信息进行学习,还使用了CTC进行输入到输出的映射以及网络模型参数的更新。将这种方法与语言模型相结合之后,对单词的拼写错误进行修正,能够得到更好的识别效果,使用方法">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Deep Speech的语音识别系统的实现与改进">
<meta property="og:url" content="https://hulksun.github.io/2017/04/01/speech-recognition-with-DeepSpeech/">
<meta property="og:site_name" content="HULKBLOG">
<meta property="og:description" content="摘要  Deep Speech是一个端到端的语音识别系统,该系统使用深度学习的方法取代了传统的特征提取方法,直接从根据波形文件产生的频谱图中提取特征生成对应的文字信息。该系统使用门限循环单元构建的循环神经网络能够对具有时间序列相关性的语音信息进行学习,还使用了CTC进行输入到输出的映射以及网络模型参数的更新。将这种方法与语言模型相结合之后,对单词的拼写错误进行修正,能够得到更好的识别效果,使用方法">
<meta property="og:image" content="https://hulksun.github.io/assets/img/spectrogram-processing.png">
<meta property="og:image" content="https://hulksun.github.io/assets/img/GRU.png">
<meta property="og:image" content="https://hulksun.github.io/assets/img/structure_of_DS.png">
<meta property="article:published_time" content="2017-04-01T14:12:43.000Z">
<meta property="article:modified_time" content="2020-04-09T03:10:41.374Z">
<meta property="article:author" content="Hulk Sun">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hulksun.github.io/assets/img/spectrogram-processing.png">

<link rel="canonical" href="https://hulksun.github.io/2017/04/01/speech-recognition-with-DeepSpeech/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>基于Deep Speech的语音识别系统的实现与改进 | HULKBLOG</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HULKBLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Talk is cheap, Show me the code.</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://hulksun.github.io/2017/04/01/speech-recognition-with-DeepSpeech/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hulk Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HULKBLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于Deep Speech的语音识别系统的实现与改进
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-04-01 22:12:43" itemprop="dateCreated datePublished" datetime="2017-04-01T22:12:43+08:00">2017-04-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-09 11:10:41" itemprop="dateModified" datetime="2020-04-09T11:10:41+08:00">2020-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DeepLearning/" itemprop="url" rel="index">
                    <span itemprop="name">DeepLearning</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>6.9k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>6 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>  Deep Speech是一个端到端的语音识别系统,该系统使用深度学习的方法取代了传统的特征提取方法,直接从根据波形文件产生的频谱图中提取特征生成对应的文字信息。该系统使用门限循环单元构建的循环神经网络能够对具有时间序列相关性的语音信息进行学习,还使用了CTC进行输入到输出的映射以及网络模型参数的更新。将这种方法与语言模型相结合之后,对单词的拼写错误进行修正,能够得到更好的识别效果,使用方法也更加简单。</p>
<p><strong>关键词</strong>：语音识别  深度学习  循环神经网络  CTC  门限循环单元  随机梯度下降  语言模型</p>
<a id="more"></a>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>Deep Speech is an end-to-end speech recognition system that uses a depth-of-learning method instead of a traditional feature extraction method to generate the corresponding textual information directly from the spectral map generated from the waveform file. The cyclic neural network constructed by the threshold cycle unit can be used to study the speech information with time series correlation. It also uses the CTC to perform the input to output mapping and the updating of the network model parameters. Combining this method with the language model, we can correct the misspelling of the word and get a better recognition result, and the method is more simple.</p>
<p><strong>Keywords</strong>：Speech Recognition, Deep learning, recurrent neural network, CTC, Gated Recurrent Unit, Random gradient descent, Language model</p>
<h1 id="0-研究背景及现状"><a href="#0-研究背景及现状" class="headerlink" title="0 研究背景及现状"></a>0 研究背景及现状</h1><p>  这项工作的灵感来自之前的深度学习和语音识别的相关工作。单向的神经网络声学模型在20多年前被探索, 循环神经网络和卷积神经网络也在同一时间用于语音识别。最近DNN已经成为ASR中的一个重要部分,几乎所有最先进的语音工作都包含某种形式的深层神经网络。卷积网络也被发现有益于声学模型。循环神经网络,尤其是LSTM,一开始只是应用在经典的语音识别器上,并与卷积层的特征提取相结合取得的不错的效果。</p>
<p>  端对端语音识别是一个很活跃的研究领域,在对DNN-HMM的结果进行处理之后能够得到很好的识别效果。目前有两种方法将可变长度音频序列直接映射到可变长度的文字序列。</p>
<p>  第一种是RNN编码器解码器,首先编码器将输入序列映射到固定长度向量,然后解码器将固定长度向量扩展为输出预测序列。解码器使用的注意机制极大地提高了系统的性能,特别是对于很长输入或输出序列。在语音识别任务中,带有注意力机制的编码器解码器RNN在预测音素和字素两个方面都有不错的效果。</p>
<p>  另一种常用的将可变长度的音频输入映射到可变长度输出的技术是使用CTC损失函数对RNN模型的时序信息进行处理。CTC-RNN模型在端到端语音识别中预测字母输出时表现良好。CTC-RNN模型也已被证明能够有效预测音素,但是在这种情况下仍然需要词典进行处理。此外,使用从GMM-HMM进行逐帧对齐的DNN交叉熵网络对CTC-RNN网络进行预训练是非常必要的。在本文中,Deep Speech提出了一种从零开始训练CTC-RNN网络的方法,不需要用于预训练的帧对齐。</p>
<h1 id="1-系统实现及改进"><a href="#1-系统实现及改进" class="headerlink" title="1 系统实现及改进"></a>1 系统实现及改进</h1><h2 id="1-1-数据预处理"><a href="#1-1-数据预处理" class="headerlink" title="1.1 数据预处理"></a>1.1 数据预处理</h2><p>  深度神经网络能否有良好的学习效果的决定性因素之一就是训练集的大小。如果训练集的规模太小,达不到网络模型参数的要求,那么神经网络将难以从训练集中提取足够的特征进行学习,在实际应用时也达不到很好的效果。在训练Deep Speech时,我们使用了LibriSpeech语料库,该语料库包含了不同时间长度的阅读语音的波形文件和对应的文本信息,其中最短的语音有2s,最长的语音达20s,两万六千多条不同的语音总共时间有960小时。</p>
<p>  为了便于神经网络的处理,我们将波形文件转换成对应的频谱图输入到神经网络中。首先将20ms长度的hanning窗口作为一帧,每一帧内使用快速傅里叶变换计算各个频率的能量值,多个能量值叠加即可获得该帧所对应的频谱图。然后以10ms为步长滑动hanning窗口,分别产生每个窗口的频谱图。最后多个频谱图按时间顺序拼接起来就可生成一段语音对应的频谱图。</p>
<center>
<img src="/assets/img/spectrogram-processing.png"/>
<br>
图1.1
</center>

<h2 id="1-2-GRU"><a href="#1-2-GRU" class="headerlink" title="1.2 GRU"></a>1.2 GRU</h2><p>  门限循环单元GRU（Gated Recurrent Unit）可以看成是LSTM的变种,GRU使用Update Gate来替代LSTM中的Forget Gate和Input Gate。把Cell State和隐状态$h_{t}$进行合并,在计算当前时刻新信息的方法和LSTM有所不同。下图是GRU更新$h_{t}$的过程： </p>
<center>
<img src="/assets/img/GRU.png"/>
<br>
图1.2
</center>

<p>GRU 具体更新过程如下:</p>
<ul>
<li>首先GRU中控制数据流方向的两个门,分别是 $r_{t}$(Reset Gate)和 $z_{t}$(Update Gate),计算方法和LSTM中门的计算方法一致：</li>
</ul>
<p>$$r_{t}=\sigma \left( W^{r}x_{t}+U^{r}h_{t-1}\right)$$</p>
<p>$$z_{t}=\sigma \left( W^{z}x_{t}+U^{z}h_{t-1}\right)$$</p>
<ul>
<li>其次是计算候选隐藏层$\widetilde{h_{t}}$(Candidate Hidden Layer）,这个候选隐藏层和LSTM中的$\widetilde{C_{t}}$是类似,可以看成是当前时刻的新信息,其中$r_{t}$用来控制需要保留多少之前的记忆,如果$r_{t}$为0,那么$h_{t}$只包含当前词的信息：</li>
</ul>
<p>$$\begin{align<em>} \widetilde{h_{t}}=\tanh \left( Wx_{t}+r_{t}Uh_{t-1}\right) \end{align</em>} $$</p>
<ul>
<li>最后$z_{t}$控制需要从前一时刻的隐藏层$h_{t-1}$中遗忘多少信息,需要加入多少当前时刻的隐藏层信息$\widetilde{h_{t}}$,最后得到$h_{t}$,直接得到最后输出的隐藏层信息,这里与LSTM的区别是GRU中没有Output Gate：</li>
</ul>
<p>$$\begin{align<em>} h_{t}=Z_{t}\otimes h_{t}+(1-Z_{t})\otimes \widetilde{h_{t}}\end{align</em>}$$</p>
<p>  如果Reset Gate接近0,那么之前的隐藏层信息就会丢弃,允许模型丢弃一些和未来无关的信息；Update Gate控制当前时刻的隐藏层输出需要保留多少之前的隐藏层信息, 若$z_{t}$接近1相当于我们之前把之前的隐藏层信息拷贝到当前时刻,可以学习长距离依赖。一般来说那些具有短距离依赖的单元ResetGate比较活跃,如果$r_{t}$为1,而$z_{t}$为0,那么相当于变成了一个标准的RNN,能处理短距离依赖,具有长距离依赖的单元Update Gate比较活跃。</p>
<h2 id="1-3-CTC"><a href="#1-3-CTC" class="headerlink" title="1.3 CTC"></a>1.3 CTC</h2><p>  许多现实世界的序列学习任务是从有噪声的、未分段的输入数据中预测其标签序列。 例如,在语音识别领域,声学信号被转录为单词或字单位。递归神经网络（RNN）是非常适合这样的任务的具有很强的学习能力的神经网络。然而,由于RNN需要预分段的训练数据,并且要做后处理将其输出转换成标签序列,其适用性一直受到限制。CTC（Connectionist Temporal Classification）提出了一个用于训练RNN来直接标记未分段的输入序列的方法,从而解决以上两个问题。</p>
<p>  一个CTC网络具有SoftMax输出层,该层比label集合L多出一个unit。对于|L|个units的触发被解释为在特定的时刻观察到对应的label的概率,对于多余的unit的触发被看作是观察到空格或者no label的概率。总的来说,这些输出定义了将label序列对齐到输入序列的全部可能方法的概率。任何一个label序列的总概率,可以看作是它的不同对齐形式对应的全部概率累加。</p>
<p>  对于一个给定的输入序列x,长度为T,定义一个RNN网络,m个输入,n个输出,权重向量w作为一种映射关系:$N_{W}:（R^m）^T\to (R^n)^T$。设$y=N_{w}(x)$为网络的输出序列,$y_{k}^t$表示神经单元k在t时刻的输出值,其含义是在t时刻观察到label k的概率,这个输出值表示长度为T的序列集合$L^T$在字母集合$L^{‘T}=L \bigcup {blank}$ 上的概率分布：</p>
<p>$$p(\pi|x)=\prod_{t=1}^Ty_{\pi_{t}}^t,\forall\pi \in L^{‘T}$$</p>
<p>  现在,我们把$L^{‘T}$中的元素看作路径paths并且用π表示。公式的假设是,给定网络的中间状态（internalstate）,在不同时刻的网络输出是条件独立的。这保证了输出层不存在到它自身或者网络的反馈链接。</p>
<p>  下一步是定义一个多对一的映射$\beta:L^{‘T}\to L^{\leq T}$,其中后者是可能的label序列的集合。我们可以简单通过删除全部的blank和重复路径path中的label来实现,例如$\beta (a-ab-)=\beta (-aa–abb)=abb$。直观来说,这等价于输出一个新的label,从预测no label变为预测a label,或者从预测a label到预测另外一个label。</p>
<p>最终,我们用映射β来定义一个给定的label序列$l \in L^{\leq T}$的条件概率作为与它对应的全部paths的概率和：</p>
<p>$$p(l|x)=\sum _{\pi \in \beta^{-1}(l)}(p(\pi|x))$$</p>
<p>得到多个label序列的概率之后使用一个分类器选择出对于输入序列x最可能的label序列h(x)：</p>
<p>$$h(x)=arg\max_{l\in L^{\leq T}} p(l|x)\approx\beta(arg\max_{\pi\in N^{t}}p(\pi|x))$$</p>
<p>在CTC中使用了最大似然的方法来更新神经网络模型的参数：</p>
<p>$$L(x,y;\theta)=-\log \sum_{l\in Align(x,y)} \prod_{t}^{T}p_{ctc}(l_{t}|x;\theta)$$</p>
<p>其中Align(x, y)表示输入x通过CTC得到的输出y的所有可能性的集合。 </p>
<h2 id="1-4-系统结构"><a href="#1-4-系统结构" class="headerlink" title="1.4 系统结构"></a>1.4 系统结构</h2><p>基于Deep Speech的语音识别的系统网络结构如图所示。</p>
<center>
<img src="/assets/img/structure_of_DS.png" width = "30%"/>
<br>
图1.3
</center>
  首先将语音的波形文件转换成频谱图,然后使用一个一维卷积层进行语音信号的领域滤波；接下来的三层隐含层由GRU构成,每层包含1000个GRU单元；然后使用全连接层进行全连接操作；将全连接的输出值作为CTC的输入,经由CTC计算得到预测的文字信息。由于整个网络是以音素为预测单位,即通过语音某一帧预测其对应的字母,所以预测结果并不能保证其单词词法上的准确性,为了提高最终结果的准确性,在Deep Speech的基础上加上Spell Corrector对预测的文本进行单词拼写纠正。

<h1 id="2-实验过程及结果"><a href="#2-实验过程及结果" class="headerlink" title="2 实验过程及结果"></a>2 实验过程及结果</h1><h2 id="2-1数据集"><a href="#2-1数据集" class="headerlink" title="2.1数据集"></a>2.1数据集</h2><p>  训练该神经网络模型的数据集来自LibriSpeech Corpus,数据集内容为文章阅读录音,语言为英语,语音的时间长度范围是从0到20s,采样频率为16kHz,声道数为单声道。我们将该数据集分为三个部分：训练集、验证集、测试集。训练集中的数据由大约28000条录音片段构成,总共时长大约800小时；验证集中的数据由2800多条录音片段构成,总共时长大约90小时；测试集中的数据由2700多条录音片段构成,总共时长大约90小时。</p>
<h2 id="2-2-实验过程"><a href="#2-2-实验过程" class="headerlink" title="2.2 实验过程"></a>2.2 实验过程</h2><p>  实验过程中使用的是百度研究所的Deep Speech开源代码,该代码使用的深度学习框架是Keras 框架,编程语言为python。</p>
<p>  在进行一维卷积操作时,卷积核大小为11,移动步长为2 ,激活函数使用的是ReLu。<br>我们在每一个隐含层设置不同的神经单元个数进行了多次试验,设置不同的学习率来加快网络收敛的速度。每一次训练的Batch Size大小为16,迭代次数为1780,epoch为20。</p>
<p>  我们利用该神经网络做出了一个C/S模式的小应用。在客户端有两种提交数据的方式：录音提交和选择音频文件提交。服务器端将客户端提交来的音频文件输入到DeepSpeech中进行处理并产生预测的文本信息返回给客户端,客户端接收信息后显示在界面上。为了对比识别效果,音频文件同时会提交给百度语音识别API并返回结果然后显示。</p>
<h2 id="2-3-实验结果"><a href="#2-3-实验结果" class="headerlink" title="2.3 实验结果"></a>2.3 实验结果</h2><p>  每一个epoch耗时大约1.5个小时,整个训练过程耗时30小时。</p>
<p>  由于受到数据集规模的限制,训练出来的模型在实际测试中的效果并不好。但是通过调整学习率、神经元个数、加单词拼写修正等方法,识别准确性有一定的提高。</p>
<table>
<thead>
<tr>
<th align="center">序号</th>
<th align="center">学习率</th>
<th align="center">神经元个数</th>
<th align="center">是否有单词纠正</th>
<th align="center">测试准确率</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">1e-6</td>
<td align="center">1000</td>
<td align="center">否</td>
<td align="center">0.42</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">1e-5</td>
<td align="center">1000</td>
<td align="center">否</td>
<td align="center">0.57</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">1e-5</td>
<td align="center">2048</td>
<td align="center">否</td>
<td align="center">0.51</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">1e-5</td>
<td align="center">1000</td>
<td align="center">是</td>
<td align="center">0.62</td>
</tr>
</tbody></table>
<p>  从表中可以看出,神经单元个数相同时,学习率较小的网络有更好的准确性,这是因为在相同的epoch下,学习率大的网络收敛速度更快,预测值与实际值的差距更小,从而能得到更好的模型参数。在学习率系统的情况下,神经元个数多的网络模型准确率反而更小,可能是因为数据集太小的缘故,数据集的规模达不到网络模型参数的规模,神经网络不能从数据集中学习到足够的特征来更新网络模型参数。</p>
<h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h1><p>通过对Deep Speech的实现和改进,体会和启发如下：</p>
<ol>
<li>深度学习的特征提取方法比传统的手工特征提取方法更加简单,效果也更好,但是深度学习方法对数据集的依赖性太大。只有数据集的规模达到神经网络模型的参数的规模才能提取足够多的特征供神经网络学习。</li>
<li>在处理具有时间序列上相关性的数据时可以使用由GRU或者LSTM构成的循环神经网络,循环神经网络能够很好的保持长期依赖。例如在语音识别任务中,“I”后面接“am”的概率要远大于接“was”的概率,这样就可以通过循环神经网络来维持“I am”这种依赖关系。</li>
<li>在编码过程中学会了python语言的使用,了解了如何通过Keras构建深度神经网络,学会了C/S模式的应用程序开发。</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Amodei, Dario, et al. “Deep speech 2: End-to-end speech recognition in English and mandarin.” arXiv preprint arXiv:1512.02595 (2015).</p>
<p>[2] Graves, Alex, et al. “Connectionist temporal classification: labeling unsegmented sequence data with recurrent neural networks.” Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</p>
<p>[3] Hori, Takaaki, and Atsushi Nakamura. “Speech recognition algorithms using weighted finite-state transducers.” Synthesis Lectures on Speech and Audio Processing 9.1 (2013): 1-162.</p>
<p>[4] Panayotov, Vassil, et al. “Librispeech: an ASR corpus based on public domain audio books.” 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015.</p>
<p>[5] Chung, Junyoung, et al. “Empirical evaluation of gated recurrent neural networks on sequence modeling.” arXiv preprint arXiv:1412.3555 (2014).</p>
<p>[6] Hannan, Awni, et al. “Deep speech: Scaling up end-to-end speech recognition.” arXiv preprint arXiv:1412.5567 (2014).</p>
<p>[7] Schuster, Mike, and Kuldip K. Paliwal. “Bidirectional recurrent neural networks.” IEEE Transactions on Signal Processing 45.11 (1997): 2673-2681.</p>

    </div>

    
    
    
        <div class="reward-container">
  <div>晚上加鸡腿！</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/assets/img/pay.png" alt="Hulk Sun WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/assets/img/pay.png" alt="Hulk Sun Alipay">
        <p>Alipay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/DeepLearning/" rel="tag"># DeepLearning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2017/04/04/DeepNet-ObjectDetection/" rel="next" title="深度学习方法的对象检测与特征提取">
      深度学习方法的对象检测与特征提取 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80ODMyMC8yNDgxNA=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#摘要"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Abstract"><span class="nav-number">2.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#0-研究背景及现状"><span class="nav-number">3.</span> <span class="nav-text">0 研究背景及现状</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-系统实现及改进"><span class="nav-number">4.</span> <span class="nav-text">1 系统实现及改进</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-数据预处理"><span class="nav-number">4.1.</span> <span class="nav-text">1.1 数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-GRU"><span class="nav-number">4.2.</span> <span class="nav-text">1.2 GRU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-CTC"><span class="nav-number">4.3.</span> <span class="nav-text">1.3 CTC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-系统结构"><span class="nav-number">4.4.</span> <span class="nav-text">1.4 系统结构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-实验过程及结果"><span class="nav-number">5.</span> <span class="nav-text">2 实验过程及结果</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1数据集"><span class="nav-number">5.1.</span> <span class="nav-text">2.1数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-实验过程"><span class="nav-number">5.2.</span> <span class="nav-text">2.2 实验过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-实验结果"><span class="nav-number">5.3.</span> <span class="nav-text">2.3 实验结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-总结"><span class="nav-number">6.</span> <span class="nav-text">3 总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文献"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hulk Sun</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hulksun" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hulksun" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:884082105@qq.com" title="E-Mail → mailto:884082105@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2016 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hulk Sun</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
